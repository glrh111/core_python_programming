# 网站架构

+ 了解WSGI协议
+ 主流的Python应用服务器的特点和适用方法
+ 使用Nginx和Python应用服务器部署Flask应用
+ 介绍豆瓣开源的Libmc和豆瓣常用的缓存适用方法
+ 举例说明Redis的几个应用场景，包含适用MessagePack进行序列化和反序列化
+ 介绍适用NoSQL的原因和场景
+ 适用pymongo，并用Mongoengine重构文件托管服务的模型
+ Mongodb索引，高可用和分片的经验
+ 以豆瓣的基础架构为原型，展示大型主流网站的结构模式，并详细介绍相关重要模式，以及Web前端的性能优化经验。

## Python应用服务器

Python的Web框架自带的Web服务器的目的是用于开发，而不是生产环境。

### WSGI协议

WSGI Python Web Server Gateway Interface PEP333，规定了一种在Web服务器和Web应用程序/框架之间推荐的标准接口，
以确保Web应用程序在不同的Web服务器之间具有可移植性。

WSGI是同步接口，所以Tornado的WSGI容器无法实现异步。?存疑

### 常见的WSGI容器

#### Gunicorn

易于配置，兼容性好，CPU消耗很少，在豆瓣使用广泛。支持多种worker模式，推荐以下几种：
+ 同步worker：默认模式，一次只处理一个请求
+ 异步worker：通过Eventlet，Gevent实现的异步模式
+ 异步IO worker：目前支持gthread，gaiohttp两种类型

```
# gunicorn [OPTIONS] MODULE_NAME:VARIABLE_NAME

from flask import Flask
app = Flask(__name__)

@app.route('/heihei')
def wocao():
    return "nihao"

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=9000)

# $ gunicorn --workers=3 chapter_6.app:app -b 0.0.0.0:9000
```

worker 的数量，推荐CPU个数(或者核心数量) * 2 + 1 (为毛http://docs.gunicorn.org/en/latest/design.html#how-many-workers)
大概意思是：对于一个核心，一个worker在读取或者写入socket，另一个在处理请求。

CPU个数使用如下方式获取

`python -c 'import multiprocessing;print multiprocessing.cpu_count()'`

#### uWSGI

使用C编写，实现了自有的uwsgi协议，组件丰富，核心组件包含进程管理，监控，IPC等。

```
uwsgi --http 0.0.0.0:9000 --wsgi-file chapter_6/app.py --callable app --processes 4 --threads 2 --stats 0.0.0.0:5000

# --http 和 --http-socket: 裸跑uwsgi使用http，它将请求转发给workers。和nginx一起使用的话，使用--http-socket 选项
# 合理的进程数和线程数需要通过不断尝试得出最优值 uwsgitop 是这方面的好工具。
# 查看stats输出：uwsgitop 0.0.0.0:5000
```

## Web服务器Nginx

Python使用的Web服务器主要有 Apache，Nginx，Tengine

### Web服务器与应用服务器

1. Web服务器负责处理HTTP协议，应用服务器既可以处理HTTP内容，也能处理其他协议，如RPC
2. Web服务器用于处理静态页面的内容，对于脚本语言产生的动态内容，它通过WSGI接口交给应用服务器处理
3. 一般应用服务器都集成了Web服务器，自带的应用服务器甚至可以支持应用级别的功能，比如连接池，事务支持，消息服务等。
但集成Web服务器的目的是调试方便，应用服务器不能直接在生产环境使用。

### Why Nginx？

Nginx是发布于2004年的开源、高性能的HTTP服务器，和反向代理，还可以用来作为IMAP和POP3的代理服务器。流行的原因：
+ 作为Web服务器，它处理静态文件，索引文件的效率非常高。
+ Nginx的设计非常注重效率，支持epoll,kqueue等网络I/O模型，可以最大支持5W个并发连接，并且只占用很少的内存资源
+ 稳定性高，宕机的概率很低
+ 强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力
+ 配置简洁。配置文件通俗易懂，上手很容易。
+ 支持热部署，可以再不间断服务器的情况下对软件进行升级。
+ 提供健康检查支持，当后端出现问题时，就不再往这个后端分发请求，并且还会做后续的检查，知道这个后端恢复正常。

### 正向代理与反向代理

+ 正向代理：作为一个媒介，将互联网上获取的资源返回给相关联的客户端。代理和客户端在局域网，对于服务端是透明的。
+ 反向代理：根据客户端的请求，从后端服务器上获取资源，然后再将这些资源返回给客户端。代理和服务器在一个局域网，对客户端是透明的。

Nginx是反向代理的最佳选择，有如下作用：
+ 提高动态语言的I/O处理能力：Python, PHP, Java 这样的动态服务的I/O处理能力不高，反向代理可以缓冲请求，交给后端一个完整的HTTP请求。
同样，Nginx也可以缓冲响应，也可以减轻后端压力。
+ 加密和SSL加速
+ 安全：保护和隐藏了原始的资源服务器，还可以用作应用防火墙，防御一些网络攻击。比如DDoS
+ 负载均衡：他帮应用服务器分配请求，以达到资源使用率最佳、吞吐量最大、响应时间最小等目的
+ 缓存静态内容：代理缓存通常可以满足相当数量的网络请求，大大降低应用服务器上的负载。
+ 支持压缩：通过压缩优化，可以提高网站的访问速度，还能大大减少带宽消耗。

### 负载均衡算法 参考Page178 还有其他参数

Nginx的负载均衡模块，支持4种调度算法：

1. round_robin: Nginx默认的轮询算法，每个请求按时间顺序，逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统将其自动剔除，
使用户访问不受影响。可以通过weight制定轮询权值，weight值越大，该服务器被访问的概率越高。

2. least_conn: 请求会被发送到活跃连接数最少的服务器上，例子如下：
```
upstream backend {
    least_conn;
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;
}
```
3. ip_hash: 按访问的IP的哈希结果分配请求，所以来自同一个IP的用户会固定访问一个后端服务器。
4. hash: 按照某个键的hash结果分配，键可以是文本，变量等。
```
upstream backed {
    hash $request_uri;
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;
}
```

### uwsgi的一个例子：

```
# uwsgi --socket /tmp/uwsgi ....
http {
    upstream frontends {
        server unix:/tmp/uwsgi.sock;   # 选择unixsocket
        server 127.0.0.1:8000;         # TCP socket
    }
    server {
        location / {
            uwsgi_pass frontends;
            include uwsgi_params;
            ....
        }
    }
}
```

### Unix Socket 与 TCP Socket的性能简述

UNIX Socket 是同一台机器上不同进程的通信机制；TCP/IP Socket 是网络上不同服务器之间的进程的通信机制，在同一台机器上当然可以使用。

Postgres的以为核心开发者做过实验，证明Unix Socket的方式比TCP/IP快31%.


## 缓存系统Memcached

Memcached 是一个高性能的分布式对象缓存系统，用在动态Web应用中减轻数据库负载。通过在内存中缓存数据来减少读取数据库的次数，从而提高Web应用速度。

Memcached守护进程用C编写，常见客户端推荐如下： Page180  libmc 最快

### 安装配置libmc

docker方式启动memcached

pip install libmc

配置文件及程序示例见附件

#### 使用原生SQL缓存

### 缓存更新策略

+ 懒惰式加载：客户端先查询memcached，如果命中，返回；否则从数据库获取最新数据，写入m中并返回。
但是在高并发场景下，突然失效会让后端数据库压力骤增。
+ 主动更新：默认缓存永不失效，当有数据需要更新时，会把数据写入到memcached。也可以将更新让如消息队列里边。

### Memcached使用经验

+ 批量获取时使用mc.get_multi ...
+ 如果对缓存全部更新，可以直接升级缓存键，在缓存键字符串后边加一个版本号
+ 批量更新缓存的时候，尽量少给后端数据库带来压力，需要对缓存预热。
+ 还可以缓存HTML片段，或者缓存Mako模板的页面数据，性能更好。
+ 按照m的协议，缓存的值必须小于1M，内容可以是任意字符串。虽然libmc通过拆分支持大于1M的，但是不鼓励这么做。
+ 不鼓励使用读写删之外的接口，比如append,prepend,incr,add..., 如果使用也会给运维带来困难

## 键值对数据库Redis

基于内存的键值对存储系统，常用作数据库，缓存，消息代理。
+ 支持字符串，字典，列表，集合，有序集合，位图，地理位置，HyperLogLog
等多种数据结构
+ 支持事务，分片，主从复制，支持RDB，AOF等持久化方式
+ 支持订阅分发，Lua脚本，集群
+ 用作缓存时，和m功能类似，但是能做到一下额外的几点
  + 支持持久化。m不支持
  + 丰富的数据结构
  + 丰富的操作命令
    + 通过通配符查看线上已经存在的键，判断一个键是否存在
    + 方便获取服务器信息和统计数值 info
    + 方便通过以上工具运维
    
### Redis应用场景

有哪些场景可以用Redis代替数据库？当不需要数据库的高级功能，如
事务提供的回滚，关联查询，UPDATE操作，而且Redis可以满足该场景，
那么选择Redis。

#### 取最新N个数据的操作

使用MessagePack来做序列化/反序列化操作。
需选择cPickle是因为希望跨语言工作。

需要权衡一下，如果只缓存id信息，不需要序列化，但是需要从数据库里获取额外信息；
或者将对象都序列化进入Redis。

#### 取TOP N 操作（排行榜）

使用有序集合实现。Sorted Set。元素数量可以达到2^32-1. 复杂度如下：
+ zadd O(log(N))
+ zrevrange O(log(N)+M) M是操作元素的个数

#### 计数器

通过incr, decr, 等操作实现。

#### 实时统计

Redis的位图提供二进制操作，非常适合存储bool类型的值。
常见场景是记录用户登录状态，日后计算一段时间内的活跃用户数量。

查看附件 redis_active_user.py 

使用这种方法，200W的活跃用户数，只占用了不到5M内存。

### 分片和集群管理

单机Redis实例不能满足需要的时候，我们可以通过一致性hash(Consistent Hashing)
算法将Redis数据的键进行散列，通过hash函数，将特定的键映射到特定的Redis节点中，
这就是分片。可以借助客户端或者代理实现分片。
主要方式如下：

+ Twemproxy： Redis3之前的通用方式， 用C编写的代理。不便于运维，无法平滑扩容。
+ Redis Cluster: Redis3.0添加的集群方式。首选。使用数据分片实现。但应用不广泛。
+ Codis：豌豆荚曾经使用过。

## NoSQL数据库 MongoDB

为啥使用NoSQL？ Not Only SQL, 不适用SQL作为查询语言，
数据存储不需要预先定义模式，这在构建Web程序中极为有用。
还解决了关系型数据库本身无法克服的某些缺陷：
+ 对数据库可以进行高并发读写的需求
+ 对海量数据进行高效率存储和访问的需求
+ 高可扩展性和高可用性

而NoSQL的不足显得不那么重要，可以弥补：
+ 数据库事务一致性需求
+ 数据库的实时读写需求
+ 对复杂的SQL查询，特别是多表关联查询的需求。

### MongoDB的优点

1. 文档型存储：关系型数据库的表相当于一个表格，每一条记录是一个元组。
Mongo中的数据存储为键值对的形式。值可以是任意类型而且可以嵌套。
2. 使用高效的二进制BSON存储数据。类似JSON格式，不过可以提供更快的
遍历速度，提供比JSON更多的内置数据类型。
3. 自带高可用及分区的解决方案，分别为副本集replica set和分片sharding
4. 基于文档的富查询语句。并且可以对文档字段建立索引。
5. 内置聚合工具。可以通过MapReduce的方式进行复杂的统计和并行计算。
6. WriedTiger Mongo3.0以后增加的数据存储引擎，高性能，可伸缩，支持压缩，
文档级锁，带来4~7倍的性能提升。
并且和原来基于内存映射技术的存储引擎（NMAP）兼容。

### ODM mongoengine

ODM Object Doc Mapping 对象文档映射

### mongo实践经验

#### 善用组合式的大文档

比如可以在一个doc里边，加入若干字段，将以前的若干记录，合并为一条。
不仅节约了空间，而且查询速度快。

#### 正确使用索引 Page 211

添加索引是为了提高查询速度。但是总是容易出现：
缺少索引，索引错误，索引太多等漏网之鱼。

日志 /var/log/mongodb/mongod.log 里边会默认记录查询时间大于100ms的记录。

也可以将慢查询记录进入分析器中：system.profile中

```
db.set_profiling_level(0)
db.system.profile.drop()
db.create_collection('system.profile', capped=True, size=10000000)
db.set_profiling_level(1)

# 获取上一周慢查询top100日志
db.system.profile.find({ 'ts': { '$gte':datetime(2016,3,14), '$lt': .. } })
.sort({millis: -1}).limit(100)
```

最左前缀原则。建立 (symbol, 1), (create_date, -1) 后，
就不需要建立 (symbol, 1) 这个索引了。

#### 高可用方案

复制replication是大多数数据库系统的标配。复制可以保证
生产环境的数据在发生故障后仍然保持可用状态。常见故障如下：
+ 服务器硬件故障
+ 计划的停机：升级系统，硬件维护，切换新服务器等。
+ 异常断电

两种复制方式：主从复制 ， 副本集。后者可以提供自动的故障转移，
即主服务器下线后，如果可能的话，将一个从节点提升为主节点。

常见副本集架构如下：
+ 一个主节点用于读写，两个从节点可读。最低配。
+ 一个主节点用于写，多个节点用于读，一个从节点用于备份。

复制不会备份！

#### 分片方案

当需求超过单台服务器能提供的70%的时候，需要考虑做分片。
把一个集合根据片键分成多个块。chunk。然后将各个块分发到分片副本集上。
+ 不要单独使用_id 或者时间戳这种有递增的属性作为片键，这样
只会将数据添加到最后一个分片上。
+ 使用随机性高且基数比较大的片键，这样避免分片承受绝大多数负载。
+ 使用多个属性作为片键。可以和_id结合
+ 使用数据文档_id的hash值。db.collection.create_index([('_id','hashed')])
但是这样对多个文档的查询，将命中所有的片键。

## 大型网站架构经验

![通用大型网站的架构](http://image.micous.com/1543125043847106560)

### 缓存

通常，用户访问的热点数据，只集中在一小部分数据上，这部分数据应该放缓存上，以减轻后端应用和数据存储的负担。
1. 本地缓存：在应用服务器中缓存热点数据，当请求访问热点数据时，可以直接使用本机的内存获得结果而不需要访问数据库。
2. 分布式缓存：应用程序通过网络访问缓存数据。因为单机无法承受大型网站的庞大数据量。
3. 反向代理：代理服务器位于网站机房之内，用户访问的地址是代理服务器地址，由代理服务器决定是从后端获取内容，或者返回缓存数据。
通常还会使用Varnish来加速应用。
4. CDN缓存：网站提交自己的缓存内容给CDN，CDN的机器分布广泛，而且能根据客户端IP自动选择缓存服务器。
在CDN上缓存网站的而一些变化少的内容，如静态资源，可以有效提升页面加载速度。

### 负载均衡

后端服务器性能参差不齐。
通过负载均衡，可以把用户的请求分发到多台后端设备上，这样就均衡了服务器的负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间的目的。

常见的负载均衡工具有：LVS，HAProxy，Nginx，对于中小型的Web应用均可胜任。复杂场景需要注意：
1. Nginx仅能支持HTTP，HTTPS，Email等协议，使用场景最小。HAProxy和LVS都能对MySQL进行均衡。
2. LVS不支持正则表达式处理，不能做动静分离。
3. HAProxy配置选项多，最灵活，使用场景最多。
4. Nginx对网络的依赖非常小，但是LVS对网络的依赖很重

### 高可用

> Keepalived 是一个基于VRRP协议来实现的LVS服务高可用方案，可以利用其来避免单点故障。一个LVS服务会有2台服务器运行Keepalived，一台为主服务器（MASTER），一台为备份服务器（BACKUP），但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候， 备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。Keepalived是VRRP的完美实现，因此在介绍keepalived之前，先介绍一下VRRP的原理。
> 参考 http://freeloda.blog.51cto.com/2033581/1280962

单个节点无法满足日益增长的业务压力，势必要让服务运行在多个节点上。
这就要求系统具有高可用性，即组成系统的而某些设备宕机或者组件失效时，并不会中断服务。
keepalived最初是LVS的扩展项目，通过对服务器池对象的健康检查，实现对失效机器，服务的故障隔离，和负载均衡器之间的切换。
类似的工具还有heartbeat。

### 业务拆分

大型网站业务场景复杂，为了提高网站的可扩展性，需要考虑业务或者产品拆分，分归到不懂的业务团队中负责。
每个应用独立开发，部署，维护，每个应用通过网络进行通信，或者使用消息队列进行分发。
业务拆分还包括对数据库的分库，其实现的成本低，但是实现的效果较好。

### 集群

使用集群是解决高并发，海量数据问题的常用手段。
当单台服务器的存储空间和处理能力不能满足要求时，不要忙不提高服务器配置，而是选择增加一台服务器来分担原服务器的访问和存储压力。

用户看到的大型网站的大部分页面，一般都不是单独的应用提供服务，整个页面事实上被分割成了多个部分，每个部分都由独立部署的服务器集群提供服务。

集群包含提供相同服务的多个服务器，既提高了并发能力，也能在某台服务器发生故障时，使用系统失效机制，或者按照负载均衡的设置，使用户感觉不到异常。

不同用途的服务器对硬件资源的要求不太一样：
+ 应用服务器需要处理大量的业务逻辑，需要更快的CPU
+ 文件服务器存储大量用户文件，需要更大的硬盘
+ 数据库服务器需要快速写入数据，和检索到要查询的数据缓存，需要更快的硬盘和更大的内存
+ 缓存服务器需要更快速获取缓存数据，只需要更大的内存。

web前端性能优化考虑三点：
1. 减少页面请求和内容请求量：HTTP开销昂贵。可以通过合并CSS，合并JS，并压缩，合并图片来减少HTTP请求数目。
合并图片的方法主要有：
  + CSS Image Sprites 多张图片合并成一个单独的图片
  + 内联图片 通过data:URL方法
  + IconFont 图标字体

2. 动静页面分离：把JS，css这样的静态资源，部署在专门的集群上。
3. 动态页面动态化：如果动态页面的访问量很大，但是更新不频繁，可以将其生成一个静态页面，然后优化。





















